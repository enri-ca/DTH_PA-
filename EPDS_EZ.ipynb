{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Intro\n",
        "\n",
        "This Jupyter Notebook has been created for the <a href=\"https://www.unibo.it/it/didattica/insegnamenti/insegnamento/2021/443749\" target=\"_blank\">90154 - Electronic Publishing and Digital Storytelling</a> course taught by **Prof. Marilena Daquino** in the framework of the 2nd year of the <a href=\"https://corsi.unibo.it/2cycle/DigitalHumanitiesKnowledge\"  target=\"_blank\">DHDK Master Degree</a>, a.a. 2021-22.<br>\n",
        "Here listed the main steps for the realization of the project **Partizione Antica**: \n",
        "https://mybinder.org/v2/gh/https%3A%2F%2Fenri-ca.github.io%2FEPDS_EZ/main\n",
        "      \n",
        "       \n",
        "    1. Data Preparation:\n",
        "          - creation of two complexive xml files for F and OA records coming from the Federico Zeri Foundation catalogues\n",
        "          - extraction from nested xml stucture of relevant information for the project and structuring them in plain tabular format\n",
        "    2. Data Elaboration: seeking for furter analysis elements via:\n",
        "          - deeper work on photographer for enhance their information\n",
        "          - deeper work on places\n",
        "          - work on unstructured annotations: NER\n",
        "     2. Data Visualization\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "D76tTDYyH-z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data preparation\n",
        "\n",
        "This research started from a **record data extraction** provided from the Federico Zeri Foundation: the original data counted 3.260 F and 2.634 OA records - respectively for the photographs, and for the depicted works of art - of the Supino Partizione Antica fund. <br>\n",
        "The original data are here published for illustrative and didactical purposes only: all the credits and reuse authorizations have to be asked to <a href=\"mailto:fondazionezeri.fototeca@unibo.it\">Federico Zeri Foundation</a>.\n",
        "\n",
        "**1.1 Creation of the F and OA complexive xml files**\n",
        "\n",
        "To allow a better management and manipulation, complexive files (via <a href=\"/content/sample_data/0_Creation_UniqeXML.xquery\" target=\"_blank\">0_Creation_UniqeXML.xquery</a> collection command) have been created putting togheter:\n",
        "\n",
        "*   all the single photograph xml files' records in the UNIQUE_F.xml**mettere_link** file\n",
        "*   all the single works of art xml files' records in the UNIQUE_OA.xml**mettere_link** file\n",
        "\n",
        "**1.2 Creation of the flat tabular dataset extracting relevant information for the project from the nested xml elements and attributes**\n",
        "\n",
        "Due to the hypernested and not consistently presence of elements at different levels, <pandas.read_xml> method was not effectively parsing what was needed.\n",
        "The <xml.etree.ElementTree> library has then been preferred because it allows to call for single elements at different nesting levels. Nevertheless, this approach presents some drawbacks as the need of a previous and deep knowledge of the database structure that does not allow to uncover unexpected correlations possible through the exploration of a comprehensive dataset.\n",
        "\n",
        "**1.3 Preliminary installation**(Uncomment the first line to install the library)\n",
        "- libraries\n",
        "- imports:\n",
        "  - xml.etree.ElementTree, pandas, csv for managing the dataset\n",
        "  - ...\n"
      ],
      "metadata": {
        "id": "TYn9-Vu-cI03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from csv import DictReader\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "F_tree = ET.parse('../resources/UNIQUE_F.xml')\n",
        "F_root = F_tree.getroot()\n",
        "F_root.attrib['test']\n",
        "\n",
        "OA_tree = ET.parse('../resources/UNIQUE_OA.xml')\n",
        "OA_root = OA_tree.getroot()\n",
        "OA_root.attrib['test2']\n",
        "\n",
        "#setting the colums' headers for the choosen elements\n",
        "header = ['sercdf:F_ser', 'sercdoa:OA_ser', 'INVN:F', 'UBFC:Fshelfmark', \n",
        "          'PVCS:OAcountry', 'PVCC:OAtown', 'PRVC:OAprev_town', 'AUFN:Faut', \n",
        "          'SGLT:Ftitle', 'SGTT:OAtitle', 'OGTT:OAtype', 'AUTB:Fsubj_main', \n",
        "          'OGTDOA:OAsubj_sub', 'AUTN:OAaut', 'ROFI:Fneg', 'OSS:Fnotes', \n",
        "          'OSS:OAnotes', 'FTAN:filename', 'NCTN:F_entry', 'NRSCHEDA:OA_entry']\n",
        "\n",
        "#setting an empty list\n",
        "data = []\n",
        "\n",
        "#function to have back the text element required if present without\n",
        "def extract_data(path):\n",
        "    #name = SCHEDA.find(path).tag\n",
        "    if SCHEDA.find(path) != None:\n",
        "         name = SCHEDA.find(path).text\n",
        "    else:\n",
        "        name = None\n",
        "    return name\n",
        "\n",
        "#iteration on UNIQUE_F SCHEDA - and on correspondig UNIQUE_OA SCHEDA - \n",
        "#for extracting elements texts, store them in a list and add it to the data\n",
        "for SCHEDA in F_root.findall('SCHEDA'):\n",
        "    oa_ser = SCHEDA.get(\"sercdoa\")\n",
        "    f_ser = SCHEDA.get(\"sercdf\")\n",
        "    inv = extract_data(\"./PARAGRAFO/INVN\")\n",
        "    container = extract_data(\"./PARAGRAFO/UBFT\")\n",
        "    shelf = extract_data(\"./PARAGRAFO/UBFC\")\n",
        "    title_f = extract_data(\"./PARAGRAFO/RIPETIZIONE/SGLT\")\n",
        "    aut_f = extract_data(\"./PARAGRAFO/RIPETIZIONE/AUFN\")\n",
        "    aut_oa = extract_data(\"./PARAGRAFO/RIPETIZIONE/AUTN\")\n",
        "    subj_main = extract_data(\"./PARAGRAFO/RIPETIZIONE/AUTB\")\n",
        "    subj_sub = extract_data(\"./PARAGRAFO/RIPETIZIONE/OGTDOA\")\n",
        "    notes_f = extract_data(\"./PARAGRAFO/OSS\")\n",
        "    neg_num = extract_data(\"./PARAGRAFO/ROFI\")\n",
        "    f_entry = extract_data(\"./PARAGRAFO/NCTN\")\n",
        "    filename = extract_data(\"./PARAGRAFO/FTAN\")\n",
        "\n",
        "    for SCHEDA in OA_root.findall('SCHEDA'):\n",
        "        if SCHEDA.get(\"sercdoa\") == oa_ser:\n",
        "            title_oa = extract_data(\"./PARAGRAFO/SGTT\")\n",
        "            date_from_oa = extract_data(\"./PARAGRAFO/DTSI\")\n",
        "            date_to_oa = extract_data(\"./PARAGRAFO/DTSF\")\n",
        "            country_oa = extract_data(\"./PARAGRAFO/PVCS\")\n",
        "            town_oa = extract_data(\"./PARAGRAFO/PVCC\")\n",
        "            prev_town_oa = extract_data(\"./PARAGRAFO/RIPETIZIONE/PRVC\")\n",
        "            type_oa = extract_data(\"./PARAGRAFO/OGTT\")\n",
        "            notes_oa = extract_data(\"./PARAGRAFO/OSS\")\n",
        "            oa_entry = extract_data(\"./PARAGRAFO/NRSCHEDA\")\n",
        "\n",
        "    row = [oa_ser, f_ser, inv, shelf, country_oa, town_oa, prev_town_oa, aut_f, \n",
        "           title_f, title_oa, type_oa, subj_main, subj_sub, aut_oa,\n",
        "           neg_num, notes_f, notes_oa, filename, f_entry, oa_entry]\n",
        "    data.append(row)\n",
        "\n",
        "#Write the data and their header in a new csv dataset\n",
        "with open('../resources/UNIQUE_new2.csv', 'w', encoding='UTF8', newline='') as tabular_data:\n",
        "    writer = csv.writer(tabular_data)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(data)\n"
      ],
      "metadata": {
        "id": "4ZW8b0GdYl6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data analysis\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WvgsBKu0cKpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Data visualization"
      ],
      "metadata": {
        "id": "sxPYRxMacLDt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuova sezione"
      ],
      "metadata": {
        "id": "pGcc1H-2cGWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "**Analyse**\n",
        "pandas library in order to examine our data.\n",
        "     \n",
        "       \n",
        "    1. Data Preparation:\n",
        "          - creation of two complexive xml files for F and OA records coming from the Federico Zeri Foundation catalogues\n",
        "          - extraction from nested xml stucture of relevant information for the project and structuring them in plain tabular format\n",
        "    2. Data Elaboration: seeking for furter analysis elements via:\n",
        "          - deeper work on photographer for enhance their information\n",
        "          - deeper work on places\n",
        "          - work on unstructured annotations: NER\n",
        "     2. Data Visualization\n"
      ],
      "metadata": {
        "id": "_CBY57CbY2B0"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kk-RBvonXIBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}